{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a1a4cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import datetime as dt\n",
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from resources import ConfigS3\n",
    "define = ConfigS3()\n",
    "\n",
    "import config as CONFIG\n",
    "import boto3\n",
    "client_s3 = boto3.client('s3',\n",
    "                    region_name=CONFIG.S3_REGION,\n",
    "                    aws_access_key_id=CONFIG.S3_ACCESS_KEY,\n",
    "                    aws_secret_access_key=CONFIG.S3_SECRET_ACCESS_KEY\n",
    "                    )\n",
    "\n",
    "PERIOD_LENGTH = 5  # minutes\n",
    "SOURCE_DIR = os.path.join('.', 'tomtom-voh')\n",
    "TRAIN_DIR = os.path.join('.', '24_06_IS_HOT_TOMTOM')\n",
    "\n",
    "if not os.path.exists(TRAIN_DIR):\n",
    "    os.makedirs(TRAIN_DIR)\n",
    "\n",
    "def velocity_to_los(velocity):\n",
    "    if velocity < 15:\n",
    "        return 'F'\n",
    "    elif velocity < 20:\n",
    "        return 'E'\n",
    "    elif velocity < 25:\n",
    "        return 'D'\n",
    "    elif velocity < 30:\n",
    "        return 'C'\n",
    "    elif velocity < 35:\n",
    "        return 'B'\n",
    "    else:\n",
    "        return 'A'\n",
    "\n",
    "\n",
    "def los_to_velocity(los):\n",
    "    los_to_velocity = {\n",
    "        'A': 35,\n",
    "        'B': 30,\n",
    "        'C': 25,\n",
    "        'D': 20,\n",
    "        'E': 15,\n",
    "        'F': 10,\n",
    "    }\n",
    "    return los_to_velocity[los] or 45\n",
    "\n",
    "\n",
    "def parse_date_and_period(timestamp):\n",
    "    ts = dt.datetime.fromtimestamp(timestamp)\n",
    "    date, time, weeekday = ts.date(), ts.time(), ts.weekday()\n",
    "\n",
    "    h, m, s = time.hour, time.minute, time.second\n",
    "\n",
    "    hour = f\"0{h}\" if h < 10 else str(h)\n",
    "    step = (m * 60 + s) // (PERIOD_LENGTH * 60)\n",
    "    m = PERIOD_LENGTH * step\n",
    "    minute = f\"0{m}\" if m < 10 else str(m)\n",
    "    period = f\"period_{hour}_{minute}\"\n",
    "    is_morning = 1 if h<=12 else 0\n",
    "    return str(date), period, weeekday, is_morning\n",
    "\n",
    "\n",
    "def reset():\n",
    "    shutil.rmtree(TRAIN_DIR)\n",
    "\n",
    "def get_period_from_timestamp(timestamp):\n",
    "\ttimestamp = dt.datetime.fromtimestamp(timestamp)\n",
    "\thour = timestamp.hour\n",
    "\tminute = timestamp.minute\n",
    "\n",
    "\tif (hour >= 0 and hour <= 5) or (hour >= 9 and hour <= 15) or (hour >= 19 and hour <= 23):\n",
    "\t\treturn \"period_{hour}\".format(hour=hour)\n",
    "\tif (hour == 24):\n",
    "\t\treturn 'period_0'\n",
    "\tif (minute >= 30):\n",
    "\t\treturn \"period_{hour}_30\".format(hour=hour)\n",
    "\treturn \"period_{hour}\".format(hour=hour)\n",
    "\n",
    "def get_seg_weather_data(timestamp, weather_data):\n",
    "    weather = \"\"\n",
    "    temperature = \"\"\n",
    "    try:\n",
    "        time_data = weather_data[str(timestamp)]\n",
    "        weather = time_data[\"weather\"][0][\"main\"]\n",
    "        temperature = time_data[\"main\"][\"temp\"]\n",
    "    except:\n",
    "        pass\n",
    "    return weather, temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d3fd4d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "checked_time_list = {\n",
    "   \"1\": [\"16:00:00\", \"19:00:00\"],\n",
    "   \"2\": [\"7:00:00\", \"10:00:00\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e2ae0423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_str_to_time(time_str):\n",
    "    return dt.datetime.strptime(time_str, '%H:%M:%S').time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "17a8366a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_times(need_to_checked_time):\n",
    "    global checked_time_list\n",
    "    checked_time = False\n",
    "    for key, value in checked_time_list.items():\n",
    "        if convert_str_to_time(value[0]) <= need_to_checked_time <= convert_str_to_time(value[1]):\n",
    "            checked_time = True\n",
    "\n",
    "    return checked_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b6a6fb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "district_dict_compare = {\n",
    "    'quan_go_vap': 'Quận Gò Vấp',\n",
    "    'huyen_binh_chanh': 'Huyện Bình Chánh',\n",
    "    'quan_2': 'Thành phố Thủ Đức',\n",
    "    'quan_binh_tan': 'Quận Tân Bình',\n",
    "    'quan_12': 'Quận 12',\n",
    "    'quan_tan_phu': 'Quận Tân Phú',\n",
    "    'quan_5': 'Quận 5',\n",
    "    'quan_tan_binh': 'Quận Tân Bình',\n",
    "    'quan_7' : 'Quận 7',\n",
    "    'quan_9': 'Thành phố Thủ Đức',\n",
    "    'quan_thu_duc': 'Thành phố Thủ Đức',\n",
    "    'quan_6': 'Quận 6',\n",
    "    'quan_1': 'Quận 1',\n",
    "    'quan_4': 'Quận 4',\n",
    "    'quan_10': 'Quận 10',\n",
    "    'huyen_hoc_mon': 'Huyện Hóc Môn',\n",
    "    'quan_3': 'Quận 3',\n",
    "    'quan_11': 'Quận 11',\n",
    "    'quan_phu_nhuan': 'Quận Phú Nhuận'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "771d3049",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_dicts = {}\n",
    "with open('selected_points.json', 'r') as f:\n",
    "    cover_points = json.load(f)\n",
    "for record in cover_points:\n",
    "    for seg_item in record[\"segment_ids\"]:\n",
    "        seg_dicts[seg_item[\"segment_id\"]] = {\n",
    "            \"district\": district_dict_compare[record[\"district\"]],\n",
    "            \"lat\": seg_item[\"lat\"],\n",
    "            \"lng\": seg_item[\"lng\"]\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d47e464",
   "metadata": {},
   "source": [
    "### For S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "334310f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_from_json(csv_file_path):\n",
    "    output = []\n",
    "    try:\n",
    "        f = csv_file_path.split('/')[-1]\n",
    "        timestamp = f.split('.')[0]\n",
    "        date, period, weekday, is_morning = parse_date_and_period(int(timestamp))\n",
    "        response = client_s3.get_object(Bucket = CONFIG.S3_BUCKET, Key = csv_file_path)\n",
    "        # Read data\n",
    "        data = json.load(response['Body'])\n",
    "        for k, v in data.items():\n",
    "            isHot = True\n",
    "            base_LOS = velocity_to_los(v['velocity'])\n",
    "            output.append([period, k, date, \n",
    "                weekday, v['velocity'], base_LOS, isHot, \"few clouds\", 27, seg_dicts[int(k)][\"district\"], seg_dicts[int(k)][\"lat\"], seg_dicts[int(k)][\"lng\"], is_morning])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "        \n",
    "    header = ['period', 'segment_id',\n",
    "                'date', 'weekday', 'tomtom_velocity', 'base_LOS', 'isHot', 'weather', 'temperature', 'district', 'lat', 'lng', 'is_morning']\n",
    "    df_result = pd.DataFrame(output, columns=header)\n",
    "    \n",
    "    return df_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2f383e",
   "metadata": {},
   "source": [
    "###  For Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "78f83348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_from_json2(csv_file_path):\n",
    "    output = []\n",
    "    try:\n",
    "        f = csv_file_path.split('/')[-1]\n",
    "        timestamp = f.split('.')[0]\n",
    "        date, period, weekday, is_morning = parse_date_and_period(int(timestamp))\n",
    "        # Read data\n",
    "        with open(csv_file_path, 'r') as json_file:\n",
    "            data = json.load(json_file)\n",
    "        for k, v in data.items():\n",
    "            isHot = True\n",
    "            base_LOS = velocity_to_los(v['velocity'])\n",
    "            output.append([period, k, date, \n",
    "                weekday, v['velocity'], base_LOS, isHot, \"few clouds\", 27, seg_dicts[int(k)][\"district\"], seg_dicts[int(k)][\"lat\"], seg_dicts[int(k)][\"lng\"], is_morning])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "        return 0\n",
    "        \n",
    "    header = ['period', 'segment_id',\n",
    "                'date', 'weekday', 'tomtom_velocity', 'base_LOS', 'isHot', 'weather', 'temperature', 'district', 'lat', 'lng', 'is_morning']\n",
    "    df_result = pd.DataFrame(output, columns=header)\n",
    "    \n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b5c2998c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"tomtom-voh/2023-05-20/1684541062.json\"\n",
    "df_result = get_df_from_json2(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "59d656eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>segment_id</th>\n",
       "      <th>date</th>\n",
       "      <th>weekday</th>\n",
       "      <th>tomtom_velocity</th>\n",
       "      <th>base_LOS</th>\n",
       "      <th>isHot</th>\n",
       "      <th>weather</th>\n",
       "      <th>temperature</th>\n",
       "      <th>district</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>is_morning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>period_07_00</td>\n",
       "      <td>23795</td>\n",
       "      <td>2023-05-20</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>C</td>\n",
       "      <td>True</td>\n",
       "      <td>few clouds</td>\n",
       "      <td>27</td>\n",
       "      <td>Quận Gò Vấp</td>\n",
       "      <td>10.830985</td>\n",
       "      <td>106.677322</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>period_07_00</td>\n",
       "      <td>60703</td>\n",
       "      <td>2023-05-20</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>C</td>\n",
       "      <td>True</td>\n",
       "      <td>few clouds</td>\n",
       "      <td>27</td>\n",
       "      <td>Quận Gò Vấp</td>\n",
       "      <td>10.831059</td>\n",
       "      <td>106.677386</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>period_07_00</td>\n",
       "      <td>23794</td>\n",
       "      <td>2023-05-20</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>C</td>\n",
       "      <td>True</td>\n",
       "      <td>few clouds</td>\n",
       "      <td>27</td>\n",
       "      <td>Quận Gò Vấp</td>\n",
       "      <td>10.830916</td>\n",
       "      <td>106.677520</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>period_07_00</td>\n",
       "      <td>60704</td>\n",
       "      <td>2023-05-20</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>C</td>\n",
       "      <td>True</td>\n",
       "      <td>few clouds</td>\n",
       "      <td>27</td>\n",
       "      <td>Quận Gò Vấp</td>\n",
       "      <td>10.830894</td>\n",
       "      <td>106.677499</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>period_07_00</td>\n",
       "      <td>60538</td>\n",
       "      <td>2023-05-20</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>C</td>\n",
       "      <td>True</td>\n",
       "      <td>few clouds</td>\n",
       "      <td>27</td>\n",
       "      <td>Quận Gò Vấp</td>\n",
       "      <td>10.830924</td>\n",
       "      <td>106.677335</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         period segment_id        date  weekday  tomtom_velocity base_LOS  \\\n",
       "0  period_07_00      23795  2023-05-20        5               27        C   \n",
       "1  period_07_00      60703  2023-05-20        5               27        C   \n",
       "2  period_07_00      23794  2023-05-20        5               27        C   \n",
       "3  period_07_00      60704  2023-05-20        5               27        C   \n",
       "4  period_07_00      60538  2023-05-20        5               27        C   \n",
       "\n",
       "   isHot     weather  temperature     district        lat         lng  \\\n",
       "0   True  few clouds           27  Quận Gò Vấp  10.830985  106.677322   \n",
       "1   True  few clouds           27  Quận Gò Vấp  10.831059  106.677386   \n",
       "2   True  few clouds           27  Quận Gò Vấp  10.830916  106.677520   \n",
       "3   True  few clouds           27  Quận Gò Vấp  10.830894  106.677499   \n",
       "4   True  few clouds           27  Quận Gò Vấp  10.830924  106.677335   \n",
       "\n",
       "   is_morning  \n",
       "0           1  \n",
       "1           1  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10d0f08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_duration_with_LOS(x, df_data):\n",
    "    try:\n",
    "        temp_data = df_data.loc[(df_data.segment_id == x.segment_id)&(df_data.is_morning == x.is_morning)].sort_values(by=['period'], ascending = False).iloc[-1]\n",
    "        if len(temp_data) > 0:\n",
    "            if temp_data.base_LOS == x.base_LOS:\n",
    "                result_duration = int(temp_data.duration_LOS) + 1\n",
    "            else:\n",
    "                result_duration = 1\n",
    "        else:\n",
    "            result_duration = 1\n",
    "    except:\n",
    "        result_duration = 1\n",
    "    return result_duration\n",
    "\n",
    "def get_duration_with_velocity(x, df_data):\n",
    "    try:\n",
    "        temp_data = df_data.loc[(df_data.segment_id == x.segment_id)&(df_data.is_morning == x.is_morning)].sort_values(by=['period'], ascending = False).iloc[-1]\n",
    "        if len(temp_data) > 0:\n",
    "            if temp_data.tomtom_velocity == x.tomtom_velocity:\n",
    "                result_duration = int(temp_data.duration_velocity) + 1\n",
    "            else:\n",
    "                result_duration = 1\n",
    "        else:\n",
    "            result_duration = 1\n",
    "    except:\n",
    "        result_duration = 1\n",
    "    return result_duration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19617bfe",
   "metadata": {},
   "source": [
    "### For S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4fd009c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result_df(list_path_files):\n",
    "    result_df = get_df_from_json(list_path_files[0][\"file_path\"])\n",
    "    for index, i in enumerate(list_path_files):\n",
    "        temp_df = get_df_from_json(i[\"file_path\"])\n",
    "        if index == 0:\n",
    "            result_df['duration_velocity'] = [1]*temp_df.shape[0]\n",
    "            result_df['duration_LOS'] = [1]*temp_df.shape[0]\n",
    "        else:\n",
    "            duration_velocity_list = temp_df.apply(get_duration_with_velocity, axis=1, args=(result_df,))\n",
    "            duration_LOS_list = temp_df.apply(get_duration_with_LOS, axis=1, args=(result_df,))\n",
    "            temp_df['duration_velocity'] = duration_velocity_list\n",
    "            temp_df['duration_LOS'] = duration_LOS_list\n",
    "            result_df = pd.concat([result_df, temp_df])\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1b9c72a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.DataFrame([])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384da74e",
   "metadata": {},
   "source": [
    "### For Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5b9895f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result_df2(list_path_files):\n",
    "    result_df = pd.DataFrame([])\n",
    "    for index, i in enumerate(list_path_files):\n",
    "        f = i[\"file_path\"].split('/')[-1]\n",
    "        timestamp = f.split('.')[0]\n",
    "        date, period, weekday, is_morning = parse_date_and_period(int(timestamp))\n",
    "        split_period = period.split('_')\n",
    "        str_time = f\"{split_period[1]}:{split_period[2]}:00\"\n",
    "        convert_time = convert_str_to_time(str_time)\n",
    "        \n",
    "        if not check_times(convert_time):\n",
    "            print(date, period, weekday, is_morning)\n",
    "            continue\n",
    "            \n",
    "        temp_df = get_df_from_json2(i[\"file_path\"])\n",
    "        if result_df.shape[0] == 0:\n",
    "            result_df = temp_df.copy()\n",
    "            result_df['duration_velocity'] = [1]*temp_df.shape[0]\n",
    "            result_df['duration_LOS'] = [1]*temp_df.shape[0]\n",
    "        else:\n",
    "            duration_velocity_list = temp_df.apply(get_duration_with_velocity, axis=1, args=(result_df,))\n",
    "            duration_LOS_list = temp_df.apply(get_duration_with_LOS, axis=1, args=(result_df,))\n",
    "            temp_df['duration_velocity'] = duration_velocity_list\n",
    "            temp_df['duration_LOS'] = duration_LOS_list\n",
    "            result_df = pd.concat([result_df, temp_df])\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a58cb2",
   "metadata": {},
   "source": [
    "### For S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7e7b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-20\n",
      "2023-05-21\n",
      "2023-05-22\n",
      "2023-05-23\n",
      "2023-05-24\n",
      "2023-05-25\n",
      "2023-05-26\n",
      "2023-05-27\n",
      "2023-05-28\n",
      "2023-05-29\n",
      "2023-05-30\n",
      "2023-05-31\n",
      "An error occurred: An error occurred (RequestTimeTooSkewed) when calling the GetObject operation: The difference between the request time and the current time is too large.\n",
      "2023-06-01\n"
     ]
    }
   ],
   "source": [
    "# list_date = [\"2023-04-19\", \"2023-04-20\", \"2023-04-21\", \"2023-04-22\", \"2023-04-23\", \"2023-04-24\", \"2023-04-25\", \"2023-04-26\", \"2023-04-27\", \"2023-04-28\", \"2023-04-29\", \"2023-04-30\", \"2023-05-01\", \"2023-05-02\", \"2023-05-03\", \"2023-05-04\", \"2023-05-05\", \"2023-05-06\", \"2023-05-07\", \"2023-05-08\", \"2023-05-09\", \"2023-05-10\", \"2023-05-11\", \"2023-05-12\", \"2023-05-13\", \"2023-05-14\", \"2023-05-15\", \"2023-05-16\", \"2023-05-17\", \"2023-05-18\", \"2023-05-19\"]\n",
    "list_date = [\"2023-05-20\", \"2023-05-21\", \"2023-05-22\", \"2023-05-23\", \"2023-05-24\", \"2023-05-25\", \"2023-05-26\", \"2023-05-27\", \"2023-05-28\", \"2023-05-29\", \"2023-05-30\", \"2023-05-31\", \"2023-06-01\", \"2023-06-02\", \"2023-06-03\", \"2023-06-04\", \"2023-06-05\", \"2023-06-06\", \"2023-06-07\", \"2023-06-08\", \"2023-06-09\", \"2023-06-10\", \"2023-06-11\", \"2023-06-12\"]\n",
    "for date_item in list_date:\n",
    "    folder_path = 'tomtom-voh/' + date_item\n",
    "    list_file = define.bucket.objects.filter(Prefix=folder_path)\n",
    "    list_path_files = []\n",
    "    print(date_item)\n",
    "    for obj in list_file:\n",
    "        f = obj.key.split('/')[-1]\n",
    "        timestamp = f.split('.')[0]\n",
    "        date, period, weekday, _ = parse_date_and_period(int(timestamp))\n",
    "        list_path_files.append(\n",
    "            {\n",
    "                \"key\":period,\n",
    "                \"file_path\": obj.key\n",
    "            }\n",
    "        )\n",
    "    list_path_files = sorted(list_path_files, key=lambda k: k['key']  , reverse=True)\n",
    "    df_result = get_result_df(list_path_files)\n",
    "    df_file_name = date_item + \".csv\"\n",
    "    df_result.to_csv(os.path.join(TRAIN_DIR, df_file_name))\n",
    "    s3_key = os.path.join(\"Result_with_velocity_23_06\", df_file_name)\n",
    "    define.upload_file_to_s3(os.path.join(TRAIN_DIR, df_file_name),s3_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b309ab20",
   "metadata": {},
   "source": [
    "### For local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646c3bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-19\n",
      "2023-04-19 period_19_50 2 0\n",
      "2023-04-19 period_19_45 2 0\n",
      "2023-04-19 period_19_40 2 0\n",
      "2023-04-19 period_19_35 2 0\n",
      "2023-04-19 period_19_30 2 0\n",
      "2023-04-19 period_19_25 2 0\n",
      "2023-04-19 period_19_20 2 0\n",
      "2023-04-19 period_19_15 2 0\n",
      "2023-04-19 period_19_10 2 0\n",
      "2023-04-19 period_19_05 2 0\n",
      "2023-04-19 period_15_55 2 0\n",
      "2023-04-19 period_10_25 2 1\n",
      "2023-04-19 period_10_20 2 1\n",
      "2023-04-19 period_10_15 2 1\n",
      "2023-04-19 period_10_10 2 1\n",
      "2023-04-20 period_06_55 3 1\n",
      "2023-04-20 period_06_50 3 1\n",
      "2023-04-20 period_06_45 3 1\n",
      "2023-04-20 period_06_40 3 1\n",
      "2023-04-20 period_06_35 3 1\n",
      "2023-04-20 period_06_30 3 1\n",
      "2023-04-20 period_06_25 3 1\n",
      "2023-04-20\n",
      "2023-04-20 period_19_55 3 0\n",
      "2023-04-20 period_19_50 3 0\n",
      "2023-04-20 period_19_45 3 0\n",
      "2023-04-20 period_19_40 3 0\n",
      "2023-04-20 period_19_30 3 0\n",
      "2023-04-20 period_19_25 3 0\n",
      "2023-04-20 period_19_20 3 0\n",
      "2023-04-20 period_19_15 3 0\n",
      "2023-04-20 period_19_10 3 0\n",
      "2023-04-20 period_19_05 3 0\n",
      "2023-04-20 period_15_55 3 0\n",
      "2023-04-20 period_10_25 3 1\n",
      "2023-04-20 period_10_20 3 1\n",
      "2023-04-20 period_10_15 3 1\n",
      "2023-04-20 period_10_10 3 1\n",
      "2023-04-20 period_10_05 3 1\n",
      "2023-04-21 period_06_55 4 1\n",
      "2023-04-21 period_06_50 4 1\n",
      "2023-04-21 period_06_45 4 1\n",
      "2023-04-21 period_06_40 4 1\n",
      "2023-04-21 period_06_35 4 1\n",
      "2023-04-21 period_06_30 4 1\n",
      "2023-04-21\n",
      "2023-04-21 period_19_50 4 0\n",
      "2023-04-21 period_19_45 4 0\n",
      "2023-04-21 period_19_40 4 0\n",
      "2023-04-21 period_19_35 4 0\n",
      "2023-04-21 period_19_30 4 0\n",
      "2023-04-21 period_19_25 4 0\n",
      "2023-04-21 period_19_20 4 0\n",
      "2023-04-21 period_19_15 4 0\n",
      "2023-04-21 period_19_10 4 0\n",
      "2023-04-21 period_19_05 4 0\n",
      "2023-04-21 period_10_25 4 1\n",
      "2023-04-21 period_10_20 4 1\n",
      "2023-04-21 period_10_15 4 1\n",
      "2023-04-21 period_10_10 4 1\n",
      "2023-04-21 period_10_05 4 1\n",
      "2023-04-22 period_06_55 5 1\n",
      "2023-04-22 period_06_45 5 1\n",
      "2023-04-22 period_06_40 5 1\n",
      "2023-04-22 period_06_35 5 1\n",
      "2023-04-22 period_06_30 5 1\n",
      "2023-04-22 period_06_25 5 1\n",
      "2023-04-22\n",
      "2023-04-22 period_19_50 5 0\n",
      "2023-04-22 period_19_45 5 0\n",
      "2023-04-22 period_19_40 5 0\n",
      "2023-04-22 period_19_35 5 0\n",
      "2023-04-22 period_19_30 5 0\n",
      "2023-04-22 period_19_25 5 0\n",
      "2023-04-22 period_19_20 5 0\n",
      "2023-04-22 period_19_15 5 0\n",
      "2023-04-22 period_19_10 5 0\n",
      "2023-04-22 period_19_05 5 0\n",
      "2023-04-22 period_15_55 5 0\n",
      "2023-04-22 period_10_25 5 1\n",
      "2023-04-22 period_10_20 5 1\n",
      "2023-04-22 period_10_15 5 1\n",
      "2023-04-22 period_10_10 5 1\n",
      "2023-04-22 period_10_05 5 1\n",
      "2023-04-23 period_06_55 6 1\n",
      "2023-04-23 period_06_50 6 1\n",
      "2023-04-23 period_06_45 6 1\n",
      "2023-04-23 period_06_40 6 1\n",
      "2023-04-23 period_06_35 6 1\n",
      "2023-04-23 period_06_30 6 1\n",
      "2023-04-23 period_06_25 6 1\n",
      "2023-04-23\n",
      "2023-04-23 period_19_50 6 0\n",
      "2023-04-23 period_19_45 6 0\n",
      "2023-04-23 period_19_40 6 0\n",
      "2023-04-23 period_19_35 6 0\n",
      "2023-04-23 period_19_30 6 0\n",
      "2023-04-23 period_19_25 6 0\n",
      "2023-04-23 period_19_20 6 0\n",
      "2023-04-23 period_19_15 6 0\n",
      "2023-04-23 period_19_10 6 0\n",
      "2023-04-23 period_19_05 6 0\n",
      "2023-04-23 period_15_55 6 0\n",
      "2023-04-23 period_10_25 6 1\n",
      "2023-04-23 period_10_20 6 1\n",
      "2023-04-23 period_10_15 6 1\n",
      "2023-04-23 period_10_10 6 1\n",
      "2023-04-23 period_10_05 6 1\n",
      "2023-04-24 period_06_55 0 1\n",
      "2023-04-24 period_06_50 0 1\n",
      "2023-04-24 period_06_45 0 1\n",
      "2023-04-24 period_06_40 0 1\n",
      "2023-04-24 period_06_35 0 1\n",
      "2023-04-24 period_06_30 0 1\n",
      "2023-04-24\n",
      "2023-04-24 period_19_55 0 0\n",
      "2023-04-24 period_19_50 0 0\n",
      "2023-04-24 period_19_45 0 0\n",
      "2023-04-24 period_19_40 0 0\n",
      "2023-04-24 period_19_35 0 0\n",
      "2023-04-24 period_19_30 0 0\n",
      "2023-04-24 period_19_25 0 0\n",
      "2023-04-24 period_19_20 0 0\n",
      "2023-04-24 period_19_15 0 0\n",
      "2023-04-24 period_19_10 0 0\n",
      "2023-04-24 period_19_05 0 0\n",
      "2023-04-24 period_10_30 0 1\n",
      "2023-04-24 period_10_25 0 1\n",
      "2023-04-24 period_10_20 0 1\n",
      "2023-04-24 period_10_15 0 1\n",
      "2023-04-24 period_10_10 0 1\n",
      "2023-04-24 period_10_05 0 1\n",
      "2023-04-25 period_06_55 1 1\n",
      "2023-04-25 period_06_50 1 1\n",
      "2023-04-25 period_06_45 1 1\n",
      "2023-04-25 period_06_40 1 1\n",
      "2023-04-25 period_06_35 1 1\n",
      "2023-04-25 period_06_30 1 1\n",
      "2023-04-25\n",
      "2023-04-25 period_19_55 1 0\n",
      "2023-04-25 period_19_50 1 0\n",
      "2023-04-25 period_19_40 1 0\n",
      "2023-04-25 period_19_35 1 0\n",
      "2023-04-25 period_19_30 1 0\n",
      "2023-04-25 period_19_25 1 0\n",
      "2023-04-25 period_19_20 1 0\n",
      "2023-04-25 period_19_15 1 0\n",
      "2023-04-25 period_19_10 1 0\n",
      "2023-04-25 period_19_05 1 0\n",
      "2023-04-25 period_10_30 1 1\n",
      "2023-04-25 period_10_25 1 1\n",
      "2023-04-25 period_10_20 1 1\n",
      "2023-04-25 period_10_15 1 1\n",
      "2023-04-25 period_10_10 1 1\n",
      "2023-04-25 period_10_05 1 1\n",
      "2023-04-26 period_06_55 2 1\n",
      "2023-04-26 period_06_50 2 1\n",
      "2023-04-26 period_06_45 2 1\n",
      "2023-04-26 period_06_40 2 1\n",
      "2023-04-26 period_06_35 2 1\n",
      "2023-04-26 period_06_30 2 1\n",
      "2023-04-26\n",
      "2023-04-26 period_19_50 2 0\n",
      "2023-04-26 period_19_45 2 0\n",
      "2023-04-26 period_19_40 2 0\n",
      "2023-04-26 period_19_35 2 0\n",
      "2023-04-26 period_19_30 2 0\n",
      "2023-04-26 period_19_25 2 0\n",
      "2023-04-26 period_19_20 2 0\n",
      "2023-04-26 period_19_15 2 0\n",
      "2023-04-26 period_19_10 2 0\n",
      "2023-04-26 period_19_05 2 0\n",
      "2023-04-26 period_15_55 2 0\n",
      "2023-04-26 period_10_25 2 1\n",
      "2023-04-26 period_10_20 2 1\n",
      "2023-04-26 period_10_15 2 1\n",
      "2023-04-26 period_10_10 2 1\n",
      "2023-04-26 period_10_05 2 1\n",
      "2023-04-27 period_06_55 3 1\n",
      "2023-04-27 period_06_50 3 1\n",
      "2023-04-27 period_06_45 3 1\n",
      "2023-04-27 period_06_40 3 1\n",
      "2023-04-27 period_06_35 3 1\n",
      "2023-04-27 period_06_30 3 1\n",
      "2023-04-27 period_06_25 3 1\n",
      "2023-04-27\n",
      "2023-04-27 period_19_50 3 0\n",
      "2023-04-27 period_19_45 3 0\n",
      "2023-04-27 period_19_40 3 0\n",
      "2023-04-27 period_19_35 3 0\n",
      "2023-04-27 period_19_30 3 0\n",
      "2023-04-27 period_19_25 3 0\n",
      "2023-04-27 period_19_20 3 0\n",
      "2023-04-27 period_19_15 3 0\n",
      "2023-04-27 period_19_10 3 0\n",
      "2023-04-27 period_19_05 3 0\n",
      "2023-04-27 period_15_55 3 0\n",
      "2023-04-27 period_10_25 3 1\n",
      "2023-04-27 period_10_20 3 1\n",
      "2023-04-27 period_10_15 3 1\n",
      "2023-04-27 period_10_10 3 1\n",
      "2023-04-27 period_10_05 3 1\n",
      "2023-04-28 period_06_55 4 1\n",
      "2023-04-28 period_06_50 4 1\n",
      "2023-04-28 period_06_45 4 1\n",
      "2023-04-28 period_06_40 4 1\n",
      "2023-04-28 period_06_35 4 1\n",
      "2023-04-28 period_06_30 4 1\n",
      "2023-04-28 period_06_25 4 1\n",
      "2023-04-28\n",
      "2023-04-28 period_19_55 4 0\n",
      "2023-04-28 period_19_50 4 0\n",
      "2023-04-28 period_19_45 4 0\n",
      "2023-04-28 period_19_40 4 0\n",
      "2023-04-28 period_19_35 4 0\n",
      "2023-04-28 period_19_30 4 0\n",
      "2023-04-28 period_19_25 4 0\n",
      "2023-04-28 period_19_20 4 0\n",
      "2023-04-28 period_19_15 4 0\n",
      "2023-04-28 period_19_10 4 0\n",
      "2023-04-28 period_19_05 4 0\n",
      "2023-04-28 period_15_55 4 0\n",
      "2023-04-28 period_10_25 4 1\n",
      "2023-04-28 period_10_20 4 1\n",
      "2023-04-28 period_10_15 4 1\n",
      "2023-04-28 period_10_10 4 1\n",
      "2023-04-28 period_10_05 4 1\n",
      "2023-04-29 period_06_55 5 1\n",
      "2023-04-29 period_06_50 5 1\n",
      "2023-04-29 period_06_45 5 1\n",
      "2023-04-29 period_06_40 5 1\n",
      "2023-04-29 period_06_35 5 1\n",
      "2023-04-29 period_06_30 5 1\n",
      "2023-04-29\n",
      "2023-04-29 period_19_55 5 0\n",
      "2023-04-29 period_19_50 5 0\n",
      "2023-04-29 period_19_45 5 0\n",
      "2023-04-29 period_19_40 5 0\n",
      "2023-04-29 period_19_35 5 0\n",
      "2023-04-29 period_19_30 5 0\n",
      "2023-04-29 period_19_25 5 0\n",
      "2023-04-29 period_19_20 5 0\n",
      "2023-04-29 period_19_15 5 0\n",
      "2023-04-29 period_19_10 5 0\n",
      "2023-04-29 period_19_05 5 0\n",
      "2023-04-29 period_10_30 5 1\n",
      "2023-04-29 period_10_25 5 1\n",
      "2023-04-29 period_10_20 5 1\n",
      "2023-04-29 period_10_15 5 1\n",
      "2023-04-29 period_10_10 5 1\n",
      "2023-04-29 period_10_05 5 1\n",
      "2023-04-30 period_06_55 6 1\n",
      "2023-04-30 period_06_50 6 1\n",
      "2023-04-30 period_06_45 6 1\n",
      "2023-04-30 period_06_40 6 1\n",
      "2023-04-30 period_06_35 6 1\n",
      "2023-04-30 period_06_30 6 1\n",
      "2023-04-30\n",
      "2023-04-30 period_19_55 6 0\n",
      "2023-04-30 period_19_45 6 0\n",
      "2023-04-30 period_19_40 6 0\n",
      "2023-04-30 period_19_35 6 0\n",
      "2023-04-30 period_19_30 6 0\n",
      "2023-04-30 period_19_25 6 0\n",
      "2023-04-30 period_19_20 6 0\n",
      "2023-04-30 period_19_15 6 0\n",
      "2023-04-30 period_19_10 6 0\n",
      "2023-04-30 period_19_05 6 0\n",
      "2023-04-30 period_10_30 6 1\n",
      "2023-04-30 period_10_25 6 1\n",
      "2023-04-30 period_10_20 6 1\n",
      "2023-04-30 period_10_15 6 1\n",
      "2023-04-30 period_10_10 6 1\n",
      "2023-04-30 period_10_05 6 1\n",
      "2023-05-01 period_06_55 0 1\n",
      "2023-05-01 period_06_50 0 1\n",
      "2023-05-01 period_06_45 0 1\n",
      "2023-05-01 period_06_40 0 1\n",
      "2023-05-01 period_06_35 0 1\n",
      "2023-05-01 period_06_30 0 1\n",
      "2023-05-01\n",
      "2023-05-01 period_19_55 0 0\n",
      "2023-05-01 period_19_50 0 0\n",
      "2023-05-01 period_19_45 0 0\n",
      "2023-05-01 period_19_40 0 0\n",
      "2023-05-01 period_19_35 0 0\n",
      "2023-05-01 period_19_30 0 0\n",
      "2023-05-01 period_19_25 0 0\n",
      "2023-05-01 period_19_20 0 0\n",
      "2023-05-01 period_19_15 0 0\n",
      "2023-05-01 period_19_10 0 0\n",
      "2023-05-01 period_19_05 0 0\n",
      "2023-05-01 period_15_55 0 0\n",
      "2023-05-01 period_10_25 0 1\n",
      "2023-05-01 period_10_20 0 1\n",
      "2023-05-01 period_10_15 0 1\n",
      "2023-05-01 period_10_10 0 1\n",
      "2023-05-01 period_10_05 0 1\n",
      "2023-05-02 period_06_55 1 1\n",
      "2023-05-02 period_06_50 1 1\n",
      "2023-05-02 period_06_45 1 1\n",
      "2023-05-02 period_06_40 1 1\n",
      "2023-05-02 period_06_35 1 1\n",
      "2023-05-02 period_06_30 1 1\n",
      "2023-05-02\n",
      "2023-05-02 period_19_55 1 0\n",
      "2023-05-02 period_19_50 1 0\n",
      "2023-05-02 period_19_45 1 0\n",
      "2023-05-02 period_19_40 1 0\n",
      "2023-05-02 period_19_30 1 0\n",
      "2023-05-02 period_19_25 1 0\n",
      "2023-05-02 period_19_20 1 0\n",
      "2023-05-02 period_19_15 1 0\n",
      "2023-05-02 period_19_10 1 0\n",
      "2023-05-02 period_19_05 1 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-02 period_10_30 1 1\n",
      "2023-05-02 period_10_25 1 1\n",
      "2023-05-02 period_10_20 1 1\n",
      "2023-05-02 period_10_15 1 1\n",
      "2023-05-02 period_10_10 1 1\n",
      "2023-05-02 period_10_05 1 1\n",
      "2023-05-03 period_06_55 2 1\n",
      "2023-05-03 period_06_50 2 1\n",
      "2023-05-03 period_06_45 2 1\n",
      "2023-05-03 period_06_40 2 1\n",
      "2023-05-03 period_06_35 2 1\n",
      "2023-05-03 period_06_30 2 1\n",
      "2023-05-03\n",
      "2023-05-03 period_19_50 2 0\n",
      "2023-05-03 period_19_45 2 0\n",
      "2023-05-03 period_19_40 2 0\n",
      "2023-05-03 period_19_35 2 0\n",
      "2023-05-03 period_19_30 2 0\n",
      "2023-05-03 period_19_25 2 0\n",
      "2023-05-03 period_19_20 2 0\n",
      "2023-05-03 period_19_15 2 0\n",
      "2023-05-03 period_19_10 2 0\n",
      "2023-05-03 period_19_05 2 0\n",
      "2023-05-03 period_15_55 2 0\n",
      "2023-05-03 period_10_25 2 1\n",
      "2023-05-03 period_10_20 2 1\n",
      "2023-05-03 period_10_15 2 1\n",
      "2023-05-03 period_10_10 2 1\n",
      "2023-05-03 period_10_05 2 1\n",
      "2023-05-04 period_06_50 3 1\n",
      "2023-05-04 period_06_45 3 1\n",
      "2023-05-04 period_06_40 3 1\n",
      "2023-05-04 period_06_35 3 1\n",
      "2023-05-04 period_06_30 3 1\n",
      "2023-05-04 period_06_25 3 1\n",
      "2023-05-04\n",
      "2023-05-04 period_19_50 3 0\n",
      "2023-05-04 period_19_45 3 0\n",
      "2023-05-04 period_19_40 3 0\n",
      "2023-05-04 period_19_35 3 0\n",
      "2023-05-04 period_19_30 3 0\n",
      "2023-05-04 period_19_25 3 0\n",
      "2023-05-04 period_19_20 3 0\n",
      "2023-05-04 period_19_15 3 0\n",
      "2023-05-04 period_19_10 3 0\n",
      "2023-05-04 period_19_05 3 0\n",
      "2023-05-04 period_15_55 3 0\n",
      "2023-05-04 period_10_25 3 1\n",
      "2023-05-04 period_10_20 3 1\n",
      "2023-05-04 period_10_15 3 1\n",
      "2023-05-04 period_10_10 3 1\n",
      "2023-05-04 period_10_05 3 1\n",
      "2023-05-05 period_06_55 4 1\n",
      "2023-05-05 period_06_50 4 1\n",
      "2023-05-05 period_06_45 4 1\n",
      "2023-05-05 period_06_40 4 1\n",
      "2023-05-05 period_06_35 4 1\n",
      "2023-05-05 period_06_30 4 1\n",
      "2023-05-05 period_06_25 4 1\n",
      "2023-05-05\n",
      "2023-05-05 period_19_50 4 0\n",
      "2023-05-05 period_19_45 4 0\n",
      "2023-05-05 period_19_40 4 0\n",
      "2023-05-05 period_19_35 4 0\n",
      "2023-05-05 period_19_30 4 0\n",
      "2023-05-05 period_19_25 4 0\n",
      "2023-05-05 period_19_20 4 0\n",
      "2023-05-05 period_19_15 4 0\n",
      "2023-05-05 period_19_10 4 0\n",
      "2023-05-05 period_19_05 4 0\n",
      "2023-05-05 period_15_55 4 0\n",
      "2023-05-05 period_10_25 4 1\n",
      "2023-05-05 period_10_20 4 1\n",
      "2023-05-05 period_10_15 4 1\n",
      "2023-05-05 period_10_10 4 1\n",
      "2023-05-05 period_10_05 4 1\n",
      "2023-05-06 period_06_55 5 1\n",
      "2023-05-06 period_06_50 5 1\n",
      "2023-05-06 period_06_45 5 1\n",
      "2023-05-06 period_06_40 5 1\n",
      "2023-05-06 period_06_35 5 1\n",
      "2023-05-06 period_06_30 5 1\n",
      "2023-05-06\n",
      "2023-05-06 period_19_55 5 0\n",
      "2023-05-06 period_19_50 5 0\n",
      "2023-05-06 period_19_45 5 0\n",
      "2023-05-06 period_19_40 5 0\n",
      "2023-05-06 period_19_35 5 0\n",
      "2023-05-06 period_19_30 5 0\n",
      "2023-05-06 period_19_25 5 0\n",
      "2023-05-06 period_19_20 5 0\n",
      "2023-05-06 period_19_15 5 0\n",
      "2023-05-06 period_19_10 5 0\n",
      "2023-05-06 period_19_05 5 0\n",
      "2023-05-06 period_10_30 5 1\n",
      "2023-05-06 period_10_25 5 1\n",
      "2023-05-06 period_10_20 5 1\n",
      "2023-05-06 period_10_15 5 1\n",
      "2023-05-06 period_10_10 5 1\n",
      "2023-05-06 period_10_05 5 1\n",
      "2023-05-07 period_06_55 6 1\n",
      "2023-05-07 period_06_50 6 1\n",
      "2023-05-07 period_06_45 6 1\n",
      "2023-05-07 period_06_40 6 1\n",
      "2023-05-07 period_06_35 6 1\n",
      "2023-05-07 period_06_30 6 1\n",
      "2023-05-07\n",
      "2023-05-07 period_19_55 6 0\n",
      "2023-05-07 period_19_50 6 0\n",
      "2023-05-07 period_19_45 6 0\n",
      "2023-05-07 period_19_35 6 0\n",
      "2023-05-07 period_19_30 6 0\n",
      "2023-05-07 period_19_25 6 0\n",
      "2023-05-07 period_19_20 6 0\n",
      "2023-05-07 period_19_15 6 0\n",
      "2023-05-07 period_19_10 6 0\n",
      "2023-05-07 period_19_05 6 0\n",
      "2023-05-07 period_10_30 6 1\n",
      "2023-05-07 period_10_25 6 1\n",
      "2023-05-07 period_10_20 6 1\n",
      "2023-05-07 period_10_15 6 1\n",
      "2023-05-07 period_10_10 6 1\n",
      "2023-05-07 period_10_05 6 1\n",
      "2023-05-08 period_06_55 0 1\n",
      "2023-05-08 period_06_50 0 1\n",
      "2023-05-08 period_06_45 0 1\n",
      "2023-05-08 period_06_40 0 1\n",
      "2023-05-08 period_06_35 0 1\n",
      "2023-05-08 period_06_30 0 1\n",
      "2023-05-08\n",
      "2023-05-08 period_19_50 0 0\n",
      "2023-05-08 period_19_45 0 0\n",
      "2023-05-08 period_19_40 0 0\n",
      "2023-05-08 period_19_35 0 0\n",
      "2023-05-08 period_19_30 0 0\n",
      "2023-05-08 period_19_25 0 0\n",
      "2023-05-08 period_19_20 0 0\n",
      "2023-05-08 period_19_15 0 0\n",
      "2023-05-08 period_19_10 0 0\n",
      "2023-05-08 period_19_05 0 0\n",
      "2023-05-08 period_15_55 0 0\n",
      "2023-05-08 period_10_25 0 1\n",
      "2023-05-08 period_10_20 0 1\n",
      "2023-05-08 period_10_15 0 1\n",
      "2023-05-08 period_10_10 0 1\n",
      "2023-05-08 period_10_05 0 1\n",
      "2023-05-09 period_06_55 1 1\n",
      "2023-05-09 period_06_50 1 1\n",
      "2023-05-09 period_06_45 1 1\n",
      "2023-05-09 period_06_40 1 1\n",
      "2023-05-09 period_06_35 1 1\n",
      "2023-05-09 period_06_30 1 1\n",
      "2023-05-09 period_06_25 1 1\n",
      "2023-05-09\n",
      "2023-05-09 period_19_50 1 0\n",
      "2023-05-09 period_19_45 1 0\n",
      "2023-05-09 period_19_40 1 0\n",
      "2023-05-09 period_19_35 1 0\n",
      "2023-05-09 period_19_30 1 0\n",
      "2023-05-09 period_19_25 1 0\n",
      "2023-05-09 period_19_20 1 0\n",
      "2023-05-09 period_19_15 1 0\n",
      "2023-05-09 period_19_10 1 0\n",
      "2023-05-09 period_19_05 1 0\n",
      "2023-05-09 period_15_55 1 0\n",
      "2023-05-09 period_10_25 1 1\n",
      "2023-05-09 period_10_20 1 1\n",
      "2023-05-09 period_10_15 1 1\n",
      "2023-05-09 period_10_10 1 1\n",
      "2023-05-09 period_10_05 1 1\n",
      "2023-05-10 period_06_55 2 1\n",
      "2023-05-10 period_06_50 2 1\n",
      "2023-05-10 period_06_45 2 1\n",
      "2023-05-10 period_06_40 2 1\n",
      "2023-05-10 period_06_35 2 1\n",
      "2023-05-10 period_06_30 2 1\n",
      "2023-05-10 period_06_25 2 1\n",
      "2023-05-10\n",
      "2023-05-10 period_19_50 2 0\n",
      "2023-05-10 period_19_45 2 0\n",
      "2023-05-10 period_19_40 2 0\n",
      "2023-05-10 period_19_35 2 0\n",
      "2023-05-10 period_19_30 2 0\n",
      "2023-05-10 period_19_25 2 0\n",
      "2023-05-10 period_19_20 2 0\n",
      "2023-05-10 period_19_15 2 0\n",
      "2023-05-10 period_19_10 2 0\n",
      "2023-05-10 period_19_05 2 0\n",
      "2023-05-10 period_15_55 2 0\n",
      "2023-05-10 period_10_25 2 1\n",
      "2023-05-10 period_10_20 2 1\n",
      "2023-05-10 period_10_15 2 1\n",
      "2023-05-10 period_10_10 2 1\n",
      "2023-05-10 period_10_05 2 1\n",
      "2023-05-11 period_06_55 3 1\n",
      "2023-05-11 period_06_50 3 1\n",
      "2023-05-11 period_06_45 3 1\n",
      "2023-05-11 period_06_40 3 1\n",
      "2023-05-11 period_06_35 3 1\n",
      "2023-05-11 period_06_30 3 1\n",
      "2023-05-11\n",
      "2023-05-11 period_19_55 3 0\n",
      "2023-05-11 period_19_50 3 0\n",
      "2023-05-11 period_19_45 3 0\n",
      "2023-05-11 period_19_40 3 0\n",
      "2023-05-11 period_19_35 3 0\n",
      "2023-05-11 period_19_30 3 0\n",
      "2023-05-11 period_19_25 3 0\n",
      "2023-05-11 period_19_20 3 0\n",
      "2023-05-11 period_19_15 3 0\n",
      "2023-05-11 period_19_10 3 0\n",
      "2023-05-11 period_19_05 3 0\n",
      "2023-05-11 period_10_25 3 1\n",
      "2023-05-11 period_10_20 3 1\n",
      "2023-05-11 period_10_15 3 1\n",
      "2023-05-11 period_10_10 3 1\n",
      "2023-05-11 period_10_05 3 1\n",
      "2023-05-12 period_06_55 4 1\n",
      "2023-05-12 period_06_50 4 1\n",
      "2023-05-12 period_06_45 4 1\n",
      "2023-05-12 period_06_40 4 1\n",
      "2023-05-12 period_06_35 4 1\n",
      "2023-05-12 period_06_30 4 1\n",
      "2023-05-12\n",
      "2023-05-12 period_19_55 4 0\n",
      "2023-05-12 period_19_50 4 0\n",
      "2023-05-12 period_19_45 4 0\n",
      "2023-05-12 period_19_40 4 0\n",
      "2023-05-12 period_19_35 4 0\n",
      "2023-05-12 period_19_30 4 0\n",
      "2023-05-12 period_19_25 4 0\n",
      "2023-05-12 period_19_20 4 0\n",
      "2023-05-12 period_19_10 4 0\n",
      "2023-05-12 period_19_05 4 0\n",
      "2023-05-12 period_10_30 4 1\n",
      "2023-05-12 period_10_25 4 1\n",
      "2023-05-12 period_10_20 4 1\n",
      "2023-05-12 period_10_15 4 1\n",
      "2023-05-12 period_10_10 4 1\n",
      "2023-05-12 period_10_05 4 1\n",
      "2023-05-13 period_06_55 5 1\n",
      "2023-05-13 period_06_50 5 1\n",
      "2023-05-13 period_06_45 5 1\n",
      "2023-05-13 period_06_40 5 1\n",
      "2023-05-13 period_06_35 5 1\n",
      "2023-05-13 period_06_30 5 1\n",
      "2023-05-13\n",
      "2023-05-13 period_19_50 5 0\n",
      "2023-05-13 period_19_45 5 0\n",
      "2023-05-13 period_19_40 5 0\n",
      "2023-05-13 period_19_35 5 0\n",
      "2023-05-13 period_19_30 5 0\n",
      "2023-05-13 period_19_25 5 0\n",
      "2023-05-13 period_19_20 5 0\n",
      "2023-05-13 period_19_15 5 0\n",
      "2023-05-13 period_19_10 5 0\n",
      "2023-05-13 period_19_05 5 0\n",
      "2023-05-13 period_10_30 5 1\n",
      "2023-05-13 period_10_25 5 1\n",
      "2023-05-13 period_10_20 5 1\n",
      "2023-05-13 period_10_10 5 1\n",
      "2023-05-13 period_10_05 5 1\n",
      "2023-05-14 period_06_55 6 1\n",
      "2023-05-14 period_06_50 6 1\n",
      "2023-05-14 period_06_45 6 1\n",
      "2023-05-14 period_06_40 6 1\n",
      "2023-05-14 period_06_30 6 1\n",
      "2023-05-14 period_06_25 6 1\n",
      "2023-05-14\n",
      "2023-05-14 period_19_50 6 0\n",
      "2023-05-14 period_19_45 6 0\n",
      "2023-05-14 period_19_40 6 0\n",
      "2023-05-14 period_19_35 6 0\n",
      "2023-05-14 period_19_30 6 0\n",
      "2023-05-14 period_19_25 6 0\n",
      "2023-05-14 period_19_20 6 0\n",
      "2023-05-14 period_19_15 6 0\n",
      "2023-05-14 period_19_10 6 0\n",
      "2023-05-14 period_19_05 6 0\n",
      "2023-05-14 period_15_55 6 0\n",
      "2023-05-14 period_10_25 6 1\n",
      "2023-05-14 period_10_20 6 1\n",
      "2023-05-14 period_10_15 6 1\n",
      "2023-05-14 period_10_10 6 1\n",
      "2023-05-14 period_10_05 6 1\n",
      "2023-05-15 period_06_55 0 1\n",
      "2023-05-15 period_06_50 0 1\n",
      "2023-05-15 period_06_45 0 1\n",
      "2023-05-15 period_06_40 0 1\n",
      "2023-05-15 period_06_35 0 1\n",
      "2023-05-15 period_06_30 0 1\n",
      "2023-05-15 period_06_25 0 1\n",
      "2023-05-15\n",
      "2023-05-15 period_19_50 0 0\n",
      "2023-05-15 period_19_45 0 0\n",
      "2023-05-15 period_19_40 0 0\n",
      "2023-05-15 period_19_35 0 0\n",
      "2023-05-15 period_19_30 0 0\n",
      "2023-05-15 period_19_25 0 0\n",
      "2023-05-15 period_19_20 0 0\n",
      "2023-05-15 period_19_15 0 0\n",
      "2023-05-15 period_19_10 0 0\n",
      "2023-05-15 period_19_05 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-15 period_15_55 0 0\n",
      "2023-05-15 period_10_25 0 1\n",
      "2023-05-15 period_10_20 0 1\n",
      "2023-05-15 period_10_15 0 1\n",
      "2023-05-15 period_10_10 0 1\n",
      "2023-05-15 period_10_05 0 1\n",
      "2023-05-16 period_06_55 1 1\n",
      "2023-05-16 period_06_50 1 1\n",
      "2023-05-16 period_06_45 1 1\n",
      "2023-05-16 period_06_40 1 1\n",
      "2023-05-16 period_06_35 1 1\n",
      "2023-05-16 period_06_30 1 1\n",
      "2023-05-16\n",
      "2023-05-16 period_19_55 1 0\n",
      "2023-05-16 period_19_50 1 0\n",
      "2023-05-16 period_19_45 1 0\n",
      "2023-05-16 period_19_40 1 0\n",
      "2023-05-16 period_19_35 1 0\n",
      "2023-05-16 period_19_30 1 0\n",
      "2023-05-16 period_19_25 1 0\n",
      "2023-05-16 period_19_20 1 0\n",
      "2023-05-16 period_19_15 1 0\n",
      "2023-05-16 period_19_10 1 0\n",
      "2023-05-16 period_19_05 1 0\n",
      "2023-05-16 period_10_25 1 1\n",
      "2023-05-16 period_10_20 1 1\n",
      "2023-05-16 period_10_15 1 1\n",
      "2023-05-16 period_10_10 1 1\n",
      "2023-05-16 period_10_05 1 1\n",
      "2023-05-17 period_06_55 2 1\n",
      "2023-05-17 period_06_50 2 1\n",
      "2023-05-17 period_06_45 2 1\n",
      "2023-05-17 period_06_40 2 1\n",
      "2023-05-17 period_06_35 2 1\n",
      "2023-05-17 period_06_30 2 1\n",
      "2023-05-17\n",
      "2023-05-17 period_19_55 2 0\n",
      "2023-05-17 period_19_50 2 0\n",
      "2023-05-17 period_19_45 2 0\n",
      "2023-05-17 period_19_40 2 0\n",
      "2023-05-17 period_19_35 2 0\n",
      "2023-05-17 period_19_30 2 0\n",
      "2023-05-17 period_19_20 2 0\n",
      "2023-05-17 period_19_15 2 0\n",
      "2023-05-17 period_19_10 2 0\n",
      "2023-05-17 period_19_05 2 0\n",
      "2023-05-17 period_10_30 2 1\n",
      "2023-05-17 period_10_25 2 1\n",
      "2023-05-17 period_10_20 2 1\n",
      "2023-05-17 period_10_15 2 1\n",
      "2023-05-17 period_10_10 2 1\n",
      "2023-05-17 period_10_05 2 1\n",
      "2023-05-18 period_06_55 3 1\n",
      "2023-05-18 period_06_50 3 1\n",
      "2023-05-18 period_06_45 3 1\n",
      "2023-05-18 period_06_40 3 1\n",
      "2023-05-18 period_06_35 3 1\n",
      "2023-05-18 period_06_30 3 1\n",
      "2023-05-18\n",
      "2023-05-18 period_19_50 3 0\n",
      "2023-05-18 period_19_45 3 0\n",
      "2023-05-18 period_19_40 3 0\n",
      "2023-05-18 period_19_35 3 0\n",
      "2023-05-18 period_19_30 3 0\n",
      "2023-05-18 period_19_25 3 0\n",
      "2023-05-18 period_19_20 3 0\n",
      "2023-05-18 period_19_15 3 0\n",
      "2023-05-18 period_19_10 3 0\n",
      "2023-05-18 period_19_05 3 0\n",
      "2023-05-18 period_10_30 3 1\n",
      "2023-05-18 period_10_25 3 1\n",
      "2023-05-18 period_10_15 3 1\n",
      "2023-05-18 period_10_10 3 1\n",
      "2023-05-18 period_10_05 3 1\n",
      "2023-05-19 period_06_55 4 1\n",
      "2023-05-19 period_06_50 4 1\n",
      "2023-05-19 period_06_45 4 1\n",
      "2023-05-19 period_06_35 4 1\n",
      "2023-05-19 period_06_30 4 1\n",
      "2023-05-19 period_06_25 4 1\n",
      "2023-05-19\n",
      "2023-05-19 period_19_50 4 0\n",
      "2023-05-19 period_19_45 4 0\n",
      "2023-05-19 period_19_40 4 0\n",
      "2023-05-19 period_19_35 4 0\n",
      "2023-05-19 period_19_30 4 0\n",
      "2023-05-19 period_19_25 4 0\n",
      "2023-05-19 period_19_20 4 0\n",
      "2023-05-19 period_19_15 4 0\n",
      "2023-05-19 period_19_10 4 0\n",
      "2023-05-19 period_19_05 4 0\n",
      "2023-05-19 period_15_55 4 0\n",
      "2023-05-19 period_10_25 4 1\n",
      "2023-05-19 period_10_20 4 1\n",
      "2023-05-19 period_10_15 4 1\n",
      "2023-05-19 period_10_10 4 1\n",
      "2023-05-19 period_10_05 4 1\n",
      "2023-05-20 period_06_55 5 1\n",
      "2023-05-20 period_06_50 5 1\n",
      "2023-05-20 period_06_45 5 1\n",
      "2023-05-20 period_06_40 5 1\n",
      "2023-05-20 period_06_35 5 1\n",
      "2023-05-20 period_06_30 5 1\n",
      "2023-05-20 period_06_25 5 1\n"
     ]
    }
   ],
   "source": [
    "list_date = [\"2023-04-19\", \"2023-04-20\", \"2023-04-21\", \"2023-04-22\", \"2023-04-23\", \"2023-04-24\", \"2023-04-25\", \"2023-04-26\", \"2023-04-27\", \"2023-04-28\", \"2023-04-29\", \"2023-04-30\", \"2023-05-01\", \"2023-05-02\", \"2023-05-03\", \"2023-05-04\", \"2023-05-05\", \"2023-05-06\", \"2023-05-07\", \"2023-05-08\", \"2023-05-09\", \"2023-05-10\", \"2023-05-11\", \"2023-05-12\", \"2023-05-13\", \"2023-05-14\", \"2023-05-15\", \"2023-05-16\", \"2023-05-17\", \"2023-05-18\", \"2023-05-19\"]\n",
    "# list_date = [\"2023-05-20\", \"2023-05-21\", \"2023-05-22\", \"2023-05-23\", \"2023-05-24\", \"2023-05-25\", \"2023-05-26\", \"2023-05-27\", \"2023-05-28\", \"2023-05-29\", \"2023-05-30\", \"2023-05-31\", \"2023-06-01\", \"2023-06-02\", \"2023-06-03\", \"2023-06-04\", \"2023-06-05\", \"2023-06-06\", \"2023-06-07\", \"2023-06-08\", \"2023-06-09\", \"2023-06-10\", \"2023-06-11\", \"2023-06-12\"]\n",
    "for date_item in list_date:\n",
    "    folder_path = 'tomtom-voh/' + date_item\n",
    "    list_file = os.listdir(folder_path)\n",
    "    list_path_files = []\n",
    "    print(date_item)\n",
    "    for obj in list_file:\n",
    "        timestamp = obj.split('.')[0]\n",
    "        date, period, weekday, _ = parse_date_and_period(int(timestamp))\n",
    "        list_path_files.append(\n",
    "            {\n",
    "                \"key\":period,\n",
    "                \"file_path\": os.path.join(folder_path, obj)\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    list_path_files = sorted(list_path_files, key=lambda k: k['key']  , reverse=True)\n",
    "    \n",
    "    df_result = get_result_df2(list_path_files)\n",
    "    df_file_name = date_item + \".csv\"\n",
    "    df_result.to_csv(os.path.join(TRAIN_DIR, df_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "3cc50e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_path_files = sorted(list_path_files, key=lambda k: k['key']  , reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "37e7b9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "period_19_55\n",
      "period_19_55\n",
      "period_19_50\n",
      "period_19_45\n",
      "period_19_40\n",
      "period_19_30\n",
      "period_19_25\n",
      "period_19_20\n",
      "period_19_15\n",
      "period_19_10\n",
      "period_19_05\n",
      "period_19_00\n",
      "period_18_55\n",
      "period_18_50\n",
      "period_18_45\n",
      "period_18_40\n",
      "period_18_35\n",
      "period_18_30\n",
      "period_18_25\n",
      "period_18_20\n",
      "period_18_15\n",
      "period_18_10\n",
      "period_18_05\n",
      "period_18_00\n",
      "period_17_55\n",
      "period_17_50\n",
      "period_17_45\n",
      "period_17_40\n",
      "period_17_35\n",
      "period_17_30\n",
      "period_17_25\n",
      "period_17_20\n",
      "period_17_15\n",
      "period_17_10\n",
      "period_17_05\n",
      "period_17_00\n",
      "period_16_55\n",
      "period_16_50\n",
      "period_16_45\n",
      "period_16_40\n",
      "period_16_30\n",
      "period_16_25\n",
      "period_16_20\n",
      "period_16_15\n",
      "period_16_10\n",
      "period_16_05\n",
      "period_16_00\n",
      "period_15_55\n",
      "period_10_25\n",
      "period_10_20\n",
      "period_10_15\n",
      "period_10_10\n",
      "period_10_05\n",
      "period_10_00\n",
      "period_09_55\n",
      "period_09_50\n",
      "period_09_45\n",
      "period_09_40\n",
      "period_09_35\n",
      "period_09_30\n",
      "period_09_25\n",
      "period_09_20\n",
      "period_09_15\n",
      "period_09_10\n",
      "period_09_05\n",
      "period_09_00\n",
      "period_08_55\n",
      "period_08_50\n",
      "period_08_45\n",
      "period_08_40\n",
      "period_08_35\n",
      "period_08_30\n",
      "period_08_25\n",
      "period_08_20\n",
      "period_08_15\n",
      "period_08_10\n",
      "period_08_05\n",
      "period_08_00\n",
      "period_07_55\n",
      "period_07_50\n",
      "period_07_45\n",
      "period_07_40\n",
      "period_07_30\n",
      "period_07_25\n",
      "period_07_20\n",
      "period_07_15\n",
      "period_07_10\n",
      "period_07_05\n",
      "period_07_00\n",
      "period_06_55\n",
      "period_06_50\n",
      "period_06_45\n",
      "period_06_40\n",
      "period_06_35\n",
      "period_06_30\n"
     ]
    }
   ],
   "source": [
    "df_result = get_result_df(list_path_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "da2c8b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_item = \"2023-04-23\"\n",
    "df_file_name = date_item + \".csv\"\n",
    "df_result.to_csv(os.path.join(TRAIN_DIR, df_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "db482746",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_key = os.path.join(\"Result\", df_file_name)\n",
    "define.upload_file_to_s3(os.path.join(TRAIN_DIR, df_file_name),s3_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb02e10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
